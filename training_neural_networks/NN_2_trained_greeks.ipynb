{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13a85da",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65327bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  \n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffc1564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>sigma</th>\n",
       "      <th>T</th>\n",
       "      <th>s0</th>\n",
       "      <th>k</th>\n",
       "      <th>t</th>\n",
       "      <th>asset</th>\n",
       "      <th>call</th>\n",
       "      <th>asset_greater_call</th>\n",
       "      <th>scaled_call</th>\n",
       "      <th>scaled_asset</th>\n",
       "      <th>tau</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>delta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>theta</th>\n",
       "      <th>vega</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324133</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.627082</td>\n",
       "      <td>2.394010</td>\n",
       "      <td>-0.608243</td>\n",
       "      <td>1.197005</td>\n",
       "      <td>0.617984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.977024</td>\n",
       "      <td>0.071240</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.997702</td>\n",
       "      <td>0.154153</td>\n",
       "      <td>0.139153</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>2.634254</td>\n",
       "      <td>-0.604191</td>\n",
       "      <td>1.179973</td>\n",
       "      <td>0.497558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.979236</td>\n",
       "      <td>0.066344</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.997924</td>\n",
       "      <td>0.142939</td>\n",
       "      <td>0.128797</td>\n",
       "      <td>0.556831</td>\n",
       "      <td>2.798086</td>\n",
       "      <td>-0.622830</td>\n",
       "      <td>1.114591</td>\n",
       "      <td>0.439232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.085137</td>\n",
       "      <td>0.133263</td>\n",
       "      <td>True</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.008514</td>\n",
       "      <td>0.912040</td>\n",
       "      <td>0.898811</td>\n",
       "      <td>0.819126</td>\n",
       "      <td>1.972797</td>\n",
       "      <td>-0.657203</td>\n",
       "      <td>0.702286</td>\n",
       "      <td>0.568942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.964273</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.996427</td>\n",
       "      <td>-0.041160</td>\n",
       "      <td>-0.053407</td>\n",
       "      <td>0.483584</td>\n",
       "      <td>3.266261</td>\n",
       "      <td>-0.644005</td>\n",
       "      <td>0.972889</td>\n",
       "      <td>0.286362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r  sigma    T    s0     k    t      asset      call  asset_greater_call  \\\n",
       "0  0.05   0.05  0.1  10.0  10.0  0.0  10.000000  0.090978                True   \n",
       "1  0.05   0.05  0.1  10.0  10.0  1.0   9.977024  0.071240                True   \n",
       "2  0.05   0.05  0.1  10.0  10.0  2.0   9.979236  0.066344                True   \n",
       "3  0.05   0.05  0.1  10.0  10.0  3.0  10.085137  0.133263                True   \n",
       "4  0.05   0.05  0.1  10.0  10.0  4.0   9.964273  0.045868                True   \n",
       "\n",
       "   scaled_call  scaled_asset   tau  moneyness        d1        d2     delta  \\\n",
       "0     0.009098           1.0  0.10   1.000000  0.324133  0.308322  0.627082   \n",
       "1     0.007124           1.0  0.09   0.997702  0.154153  0.139153  0.561255   \n",
       "2     0.006634           1.0  0.08   0.997924  0.142939  0.128797  0.556831   \n",
       "3     0.013326           1.0  0.07   1.008514  0.912040  0.898811  0.819126   \n",
       "4     0.004587           1.0  0.06   0.996427 -0.041160 -0.053407  0.483584   \n",
       "\n",
       "      gamma     theta      vega       rho  \n",
       "0  2.394010 -0.608243  1.197005  0.617984  \n",
       "1  2.634254 -0.604191  1.179973  0.497558  \n",
       "2  2.798086 -0.622830  1.114591  0.439232  \n",
       "3  1.972797 -0.657203  0.702286  0.568942  \n",
       "4  3.266261 -0.644005  0.972889  0.286362  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/final_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99211cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = data[['r','sigma','tau','k','asset']]\n",
    "y = data['call']\n",
    "#X = scaler.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6807e2",
   "metadata": {},
   "source": [
    "# NEURAL NET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c5ecf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Embedding, LSTM, Dense, BatchNormalization, Input, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow_addons.optimizers import CyclicalLearningRate\n",
    "from tensorflow.keras.initializers import RandomUniform, GlorotUniform, HeUniform\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecc8dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation, lr_0, batch_norm, dropout_rate, layer_number, neuron_number,\\\n",
    "                neuron_decrease, data_length, initializer):\n",
    "    opt = Adam(learning_rate = lr_0)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron_number, input_shape=(5,), activation = activation, \\\n",
    "                    kernel_initializer=initializer , bias_initializer=initializer))\n",
    "    for i in range(layer_number):\n",
    "        if batch_norm == True:\n",
    "            model.add(BatchNormalization())         \n",
    "        neuron_number = int(neuron_number/neuron_decrease)\n",
    "        model.add(Dense(neuron_number, activation = activation))\n",
    "    if batch_norm == True:\n",
    "        model.add(BatchNormalization()) \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, name='Final_1D_output', activation = activation))\n",
    "    model.compile(optimizer=opt,loss='mean_squared_error',\\\n",
    "                  metrics=[tfa.metrics.RSquare(dtype=tf.float32, y_shape=(1,))],\\\n",
    "                 run_eagerly=True)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def callback_list(patience):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    return early_stop\n",
    "\n",
    "def plot_loss(loss,val_loss):    \n",
    "    plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_metr(metr,val_metr,name):\n",
    "    plt.figure()\n",
    "    plt.plot(metr)\n",
    "    plt.plot(val_metr)\n",
    "    plt.title('Model'+str(name))\n",
    "    plt.ylabel(str(name))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "036addd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience_f = 2\n",
    "callbacks = callback_list(patience=patience_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd3fca",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2cab9",
   "metadata": {},
   "source": [
    "## Result from RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6887afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file_hyper = open('results/model_greeks.json', 'r')\n",
    "model_hyper = json_file_hyper.read()\n",
    "json_file_hyper.close()\n",
    "final_model = model_from_json(model_hyper)\n",
    "# load weights into new model\n",
    "final_model.load_weights(\"results/model_greeks.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddc7234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>r_square</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.411919</td>\n",
       "      <td>0.948854</td>\n",
       "      <td>0.257884</td>\n",
       "      <td>0.994612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.131595</td>\n",
       "      <td>0.997209</td>\n",
       "      <td>0.057438</td>\n",
       "      <td>0.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062123</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.031128</td>\n",
       "      <td>0.999350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.999152</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>0.999090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030624</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.999291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  r_square  val_loss  val_r_square\n",
       "0  2.411919  0.948854  0.257884      0.994612\n",
       "1  0.131595  0.997209  0.057438      0.998800\n",
       "2  0.062123  0.998683  0.031128      0.999350\n",
       "3  0.040006  0.999152  0.043548      0.999090\n",
       "4  0.030624  0.999351  0.033913      0.999291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hist = pd.read_csv('results/train_hist_greeks.csv')\n",
    "final_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a67486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neuron_number': 512, 'neuron_decrease': 2, 'lr_0': 0.001, 'layer_number': 3, 'initializer': <keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, 'dropout_rate': 0.0, 'data_length': 1000000, 'batch_size': 2048, 'batch_norm': False, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "a_file = open(\"results/search_params_greeks.pkl\", \"rb\")\n",
    "output = pickle.load(a_file)\n",
    "print(output)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1f0d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "final_model_arch = create_model(activation = output['activation'], lr_0 = output['lr_0'], \\\n",
    "                                 batch_norm = output['batch_norm'], dropout_rate = output['dropout_rate'], \\\n",
    "                                 layer_number = output['layer_number'], neuron_number = output['neuron_number'], \\\n",
    "                                    data_length = output['data_length'], neuron_decrease = output['neuron_decrease'],\\\n",
    "                                 initializer = output['initializer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61601881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(final_hist['loss'], final_hist['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197f9c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metr(final_hist['r_square'], \\\n",
    "          final_hist['val_r_square'], 'R squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3fe7c",
   "metadata": {},
   "source": [
    "## Extra fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76a7c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/wl79cq5x32dccj6j6xcb41r80000gn/T/ipykernel_28132/945307363.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  sklearn_model = KerasRegressor(build_fn = create_model)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = KerasRegressor(build_fn = create_model)\n",
    "\n",
    "params = dict(activation=[output['activation']],lr_0 = [output['lr_0']], batch_norm=[True, False], \\\n",
    "              dropout_rate = [0.0,0.1], layer_number = [output['layer_number']],\\\n",
    "              neuron_decrease = [output['neuron_decrease']], neuron_number = [output['neuron_number']], \\\n",
    "              data_length = [output['data_length']], batch_size = [output['batch_size']], \\\n",
    "              initializer = [output['initializer']] )\n",
    "\n",
    "len(ParameterGrid(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d70cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(sklearn_model, param_grid=params, cv=10, verbose=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a39e462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 10:20:40.902511: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 9s 32ms/step - loss: 2.8551 - r_square: 0.9395 - val_loss: 9.1143 - val_r_square: 0.8100\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.4333 - r_square: 0.9908 - val_loss: 1.3505 - val_r_square: 0.9718\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 31ms/step - loss: 0.2977 - r_square: 0.9937 - val_loss: 0.3256 - val_r_square: 0.9932\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2387 - r_square: 0.9949 - val_loss: 0.0875 - val_r_square: 0.9982\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 31ms/step - loss: 0.2080 - r_square: 0.9956 - val_loss: 0.0518 - val_r_square: 0.9989\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1645 - r_square: 0.9965 - val_loss: 0.1085 - val_r_square: 0.9977\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 31ms/step - loss: 0.1633 - r_square: 0.9965 - val_loss: 0.0348 - val_r_square: 0.9993\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1249 - r_square: 0.9974 - val_loss: 0.2044 - val_r_square: 0.9957\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1123 - r_square: 0.9976 - val_loss: 0.0725 - val_r_square: 0.9985\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0358 - r_square: 0.9992\n",
      "[CV 1/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.036 total time= 1.4min\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 2.6023 - r_square: 0.9449 - val_loss: 7.3908 - val_r_square: 0.8459\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.4566 - r_square: 0.9903 - val_loss: 1.0826 - val_r_square: 0.9774\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.3021 - r_square: 0.9936 - val_loss: 0.3986 - val_r_square: 0.9917\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2540 - r_square: 0.9946 - val_loss: 0.2700 - val_r_square: 0.9944\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.2553 - r_square: 0.9946 - val_loss: 0.1167 - val_r_square: 0.9976\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1502 - r_square: 0.9968 - val_loss: 0.1039 - val_r_square: 0.9978\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1515 - r_square: 0.9968 - val_loss: 0.1114 - val_r_square: 0.9977\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1447 - r_square: 0.9969 - val_loss: 0.2243 - val_r_square: 0.9953\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0959 - r_square: 0.9979\n",
      "[CV 2/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.096 total time= 1.2min\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 2.2832 - r_square: 0.9517 - val_loss: 7.9964 - val_r_square: 0.8333\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.3792 - r_square: 0.9920 - val_loss: 1.1117 - val_r_square: 0.9768\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2750 - r_square: 0.9942 - val_loss: 0.5753 - val_r_square: 0.9880\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2209 - r_square: 0.9953 - val_loss: 0.1176 - val_r_square: 0.9975\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2134 - r_square: 0.9955 - val_loss: 0.0685 - val_r_square: 0.9986\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1426 - r_square: 0.9970 - val_loss: 0.2330 - val_r_square: 0.9951\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1527 - r_square: 0.9968 - val_loss: 0.1221 - val_r_square: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 10ms/step - loss: 0.0658 - r_square: 0.9986\n",
      "[CV 3/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.066 total time= 1.1min\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 1.9912 - r_square: 0.9578 - val_loss: 6.7813 - val_r_square: 0.8586\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.4181 - r_square: 0.9911 - val_loss: 0.8404 - val_r_square: 0.9825\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.2608 - r_square: 0.9945 - val_loss: 0.3142 - val_r_square: 0.9935\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2129 - r_square: 0.9955 - val_loss: 0.1464 - val_r_square: 0.9969\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 31ms/step - loss: 0.1773 - r_square: 0.9962 - val_loss: 0.3672 - val_r_square: 0.9923\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1611 - r_square: 0.9966 - val_loss: 0.0720 - val_r_square: 0.9985\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1692 - r_square: 0.9964 - val_loss: 0.0684 - val_r_square: 0.9986\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1574 - r_square: 0.9967 - val_loss: 0.1455 - val_r_square: 0.9970\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1353 - r_square: 0.9971 - val_loss: 0.4034 - val_r_square: 0.9916\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0680 - r_square: 0.9985\n",
      "[CV 4/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.068 total time= 1.4min\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 2.0311 - r_square: 0.9571 - val_loss: 3.8306 - val_r_square: 0.9201\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 10s 34ms/step - loss: 0.3608 - r_square: 0.9924 - val_loss: 0.3881 - val_r_square: 0.9919\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.3032 - r_square: 0.9936 - val_loss: 0.3700 - val_r_square: 0.9923\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2245 - r_square: 0.9953 - val_loss: 0.3541 - val_r_square: 0.9926\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1801 - r_square: 0.9962 - val_loss: 0.0894 - val_r_square: 0.9981\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2203 - r_square: 0.9953 - val_loss: 0.4307 - val_r_square: 0.9910\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.1800 - r_square: 0.9962 - val_loss: 0.3458 - val_r_square: 0.9928\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0868 - r_square: 0.9981\n",
      "[CV 5/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.087 total time= 1.1min\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 256)              1024      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 3.1601 - r_square: 0.9329 - val_loss: 8.8113 - val_r_square: 0.8163\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.5428 - r_square: 0.9885 - val_loss: 0.7354 - val_r_square: 0.9847\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.3783 - r_square: 0.9920 - val_loss: 0.3422 - val_r_square: 0.9929\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2161 - r_square: 0.9954 - val_loss: 0.1522 - val_r_square: 0.9968\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1445 - r_square: 0.9969 - val_loss: 0.1349 - val_r_square: 0.9972\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2080 - r_square: 0.9956 - val_loss: 0.0974 - val_r_square: 0.9980\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1378 - r_square: 0.9971 - val_loss: 0.3828 - val_r_square: 0.9920\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1388 - r_square: 0.9971 - val_loss: 0.0814 - val_r_square: 0.9983\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1131 - r_square: 0.9976 - val_loss: 1.3060 - val_r_square: 0.9728\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1290 - r_square: 0.9973 - val_loss: 0.0625 - val_r_square: 0.9987\n",
      "Epoch 11/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1217 - r_square: 0.9974 - val_loss: 0.2137 - val_r_square: 0.9955\n",
      "Epoch 12/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1073 - r_square: 0.9977 - val_loss: 0.1743 - val_r_square: 0.9964\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0654 - r_square: 0.9986\n",
      "[CV 6/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.065 total time= 1.8min\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 2.9219 - r_square: 0.9378 - val_loss: 5.3432 - val_r_square: 0.8886\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.4149 - r_square: 0.9912 - val_loss: 0.3535 - val_r_square: 0.9926\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2956 - r_square: 0.9937 - val_loss: 0.0723 - val_r_square: 0.9985\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1942 - r_square: 0.9959 - val_loss: 0.7123 - val_r_square: 0.9852\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1730 - r_square: 0.9963 - val_loss: 0.1358 - val_r_square: 0.9972\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0714 - r_square: 0.9985\n",
      "[CV 7/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.071 total time=  46.1s\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 1.6989 - r_square: 0.9638 - val_loss: 5.2097 - val_r_square: 0.8914\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.3905 - r_square: 0.9917 - val_loss: 1.7750 - val_r_square: 0.9630\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.2542 - r_square: 0.9946 - val_loss: 0.2924 - val_r_square: 0.9939\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2053 - r_square: 0.9956 - val_loss: 0.1782 - val_r_square: 0.9963\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1647 - r_square: 0.9965 - val_loss: 0.1124 - val_r_square: 0.9977\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1984 - r_square: 0.9958 - val_loss: 0.0765 - val_r_square: 0.9984\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1290 - r_square: 0.9972 - val_loss: 0.9180 - val_r_square: 0.9809\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1160 - r_square: 0.9975 - val_loss: 0.0286 - val_r_square: 0.9994\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1216 - r_square: 0.9974 - val_loss: 0.9945 - val_r_square: 0.9793\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1001 - r_square: 0.9979 - val_loss: 0.0245 - val_r_square: 0.9995\n",
      "Epoch 11/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1077 - r_square: 0.9977 - val_loss: 0.3010 - val_r_square: 0.9937\n",
      "Epoch 12/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1340 - r_square: 0.9971 - val_loss: 0.1694 - val_r_square: 0.9965\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0242 - r_square: 0.9995\n",
      "[CV 8/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.024 total time= 1.8min\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 1.9093 - r_square: 0.9592 - val_loss: 6.4636 - val_r_square: 0.8718\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.4201 - r_square: 0.9910 - val_loss: 1.1481 - val_r_square: 0.9772\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2835 - r_square: 0.9939 - val_loss: 0.3532 - val_r_square: 0.9930\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2047 - r_square: 0.9956 - val_loss: 0.0800 - val_r_square: 0.9984\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1770 - r_square: 0.9962 - val_loss: 0.0720 - val_r_square: 0.9986\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2026 - r_square: 0.9957 - val_loss: 0.0764 - val_r_square: 0.9985\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1237 - r_square: 0.9974 - val_loss: 0.9003 - val_r_square: 0.9821\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0698 - r_square: 0.9985\n",
      "[CV 9/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.070 total time= 1.1min\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 10s 34ms/step - loss: 2.5746 - r_square: 0.9450 - val_loss: 4.8726 - val_r_square: 0.8973\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 9s 33ms/step - loss: 0.4531 - r_square: 0.9903 - val_loss: 0.3016 - val_r_square: 0.9936\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.2663 - r_square: 0.9943 - val_loss: 0.1560 - val_r_square: 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "282/282 [==============================] - 9s 34ms/step - loss: 0.1957 - r_square: 0.9958 - val_loss: 0.1829 - val_r_square: 0.9961\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 9s 32ms/step - loss: 0.1665 - r_square: 0.9964 - val_loss: 0.5028 - val_r_square: 0.9894\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.1695 - r_square: 0.9966\n",
      "[CV 10/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.170 total time=  47.1s\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 10s 35ms/step - loss: 2.7462 - r_square: 0.9418 - val_loss: 7.2252 - val_r_square: 0.8494\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 10s 35ms/step - loss: 0.7251 - r_square: 0.9846 - val_loss: 0.9990 - val_r_square: 0.9792\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 10s 36ms/step - loss: 0.6456 - r_square: 0.9863 - val_loss: 0.3027 - val_r_square: 0.9937\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 11s 37ms/step - loss: 0.5734 - r_square: 0.9878 - val_loss: 0.1932 - val_r_square: 0.9960\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 11s 38ms/step - loss: 0.4985 - r_square: 0.9894 - val_loss: 0.1323 - val_r_square: 0.9972\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 11s 38ms/step - loss: 0.4954 - r_square: 0.9895 - val_loss: 0.4658 - val_r_square: 0.9903\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 11s 39ms/step - loss: 0.4888 - r_square: 0.9896 - val_loss: 0.1503 - val_r_square: 0.9969\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.1520 - r_square: 0.9968\n",
      "[CV 1/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.152 total time= 1.2min\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 2.9968 - r_square: 0.9365 - val_loss: 7.9995 - val_r_square: 0.8332\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 0.7882 - r_square: 0.9833 - val_loss: 0.5178 - val_r_square: 0.9892\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 11s 40ms/step - loss: 0.6723 - r_square: 0.9858 - val_loss: 0.6438 - val_r_square: 0.9866\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 12s 41ms/step - loss: 0.5988 - r_square: 0.9873 - val_loss: 0.0942 - val_r_square: 0.9980\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 12s 42ms/step - loss: 0.5735 - r_square: 0.9879 - val_loss: 0.1601 - val_r_square: 0.9967\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 12s 42ms/step - loss: 0.5190 - r_square: 0.9890 - val_loss: 0.5734 - val_r_square: 0.9880\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.0926 - r_square: 0.9980\n",
      "[CV 2/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.093 total time= 1.2min\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_54 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 12s 43ms/step - loss: 3.2695 - r_square: 0.9309 - val_loss: 7.3792 - val_r_square: 0.8462\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 12s 44ms/step - loss: 0.7988 - r_square: 0.9831 - val_loss: 0.7625 - val_r_square: 0.9841\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 13s 45ms/step - loss: 0.6788 - r_square: 0.9856 - val_loss: 0.3049 - val_r_square: 0.9936\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 14s 49ms/step - loss: 0.6312 - r_square: 0.9867 - val_loss: 0.2990 - val_r_square: 0.9938\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 14s 50ms/step - loss: 0.5425 - r_square: 0.9885 - val_loss: 0.0659 - val_r_square: 0.9986\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 14s 50ms/step - loss: 0.4888 - r_square: 0.9897 - val_loss: 0.3082 - val_r_square: 0.9936\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 14s 51ms/step - loss: 0.4801 - r_square: 0.9898 - val_loss: 0.3271 - val_r_square: 0.9932\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 0.0651 - r_square: 0.9986\n",
      "[CV 3/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.065 total time= 1.6min\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 15s 52ms/step - loss: 2.3904 - r_square: 0.9493 - val_loss: 6.1529 - val_r_square: 0.8717\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.7427 - r_square: 0.9843 - val_loss: 0.5536 - val_r_square: 0.9885\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.6684 - r_square: 0.9858 - val_loss: 0.2702 - val_r_square: 0.9944\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 15s 53ms/step - loss: 0.5795 - r_square: 0.9877 - val_loss: 0.0573 - val_r_square: 0.9988\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 15s 55ms/step - loss: 0.4916 - r_square: 0.9896 - val_loss: 0.1013 - val_r_square: 0.9979\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 15s 55ms/step - loss: 0.5317 - r_square: 0.9887 - val_loss: 0.4804 - val_r_square: 0.9900\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 0.0579 - r_square: 0.9988\n",
      "[CV 4/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.058 total time= 1.5min\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 16s 57ms/step - loss: 3.0527 - r_square: 0.9355 - val_loss: 6.3069 - val_r_square: 0.8685\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 16s 56ms/step - loss: 0.7385 - r_square: 0.9844 - val_loss: 0.4698 - val_r_square: 0.9902\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 16s 57ms/step - loss: 0.6932 - r_square: 0.9853 - val_loss: 0.3176 - val_r_square: 0.9934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "282/282 [==============================] - 16s 57ms/step - loss: 0.5550 - r_square: 0.9883 - val_loss: 0.3826 - val_r_square: 0.9920\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 16s 58ms/step - loss: 0.5005 - r_square: 0.9894 - val_loss: 0.0683 - val_r_square: 0.9986\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 17s 59ms/step - loss: 0.5389 - r_square: 0.9886 - val_loss: 0.1349 - val_r_square: 0.9972\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 19s 68ms/step - loss: 0.4877 - r_square: 0.9897 - val_loss: 0.8892 - val_r_square: 0.9815\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0641 - r_square: 0.9986\n",
      "[CV 5/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.064 total time= 2.0min\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 22s 76ms/step - loss: 3.1043 - r_square: 0.9341 - val_loss: 6.7991 - val_r_square: 0.8583\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 21s 74ms/step - loss: 0.7185 - r_square: 0.9848 - val_loss: 0.4835 - val_r_square: 0.9899\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 21s 74ms/step - loss: 0.6516 - r_square: 0.9862 - val_loss: 0.2967 - val_r_square: 0.9938\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 21s 74ms/step - loss: 0.5413 - r_square: 0.9885 - val_loss: 0.6552 - val_r_square: 0.9863\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 22s 77ms/step - loss: 0.4723 - r_square: 0.9900 - val_loss: 0.1869 - val_r_square: 0.9961\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 22s 78ms/step - loss: 0.5068 - r_square: 0.9892 - val_loss: 0.0892 - val_r_square: 0.9981\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 22s 79ms/step - loss: 0.4611 - r_square: 0.9902 - val_loss: 0.4570 - val_r_square: 0.9905\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 22s 78ms/step - loss: 0.4240 - r_square: 0.9910 - val_loss: 0.2222 - val_r_square: 0.9954\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 0.0893 - r_square: 0.9981\n",
      "[CV 6/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.089 total time= 2.9min\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 23s 80ms/step - loss: 2.7588 - r_square: 0.9413 - val_loss: 6.9526 - val_r_square: 0.8551\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 22s 78ms/step - loss: 0.7539 - r_square: 0.9840 - val_loss: 1.0312 - val_r_square: 0.9785\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 23s 81ms/step - loss: 0.7454 - r_square: 0.9841 - val_loss: 0.1258 - val_r_square: 0.9974\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 22s 80ms/step - loss: 0.5528 - r_square: 0.9882 - val_loss: 0.6302 - val_r_square: 0.9869\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 23s 80ms/step - loss: 0.5278 - r_square: 0.9888 - val_loss: 0.1064 - val_r_square: 0.9978\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 23s 83ms/step - loss: 0.5183 - r_square: 0.9890 - val_loss: 0.3421 - val_r_square: 0.9929\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 23s 83ms/step - loss: 0.5183 - r_square: 0.9890 - val_loss: 0.8912 - val_r_square: 0.9814\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.1052 - r_square: 0.9978\n",
      "[CV 7/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.105 total time= 2.7min\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_68 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 25s 86ms/step - loss: 2.2371 - r_square: 0.9523 - val_loss: 3.7760 - val_r_square: 0.9213\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 24s 85ms/step - loss: 0.7240 - r_square: 0.9846 - val_loss: 1.8813 - val_r_square: 0.9608\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 24s 84ms/step - loss: 0.5641 - r_square: 0.9880 - val_loss: 1.0765 - val_r_square: 0.9776\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 24s 86ms/step - loss: 0.5195 - r_square: 0.9889 - val_loss: 0.2407 - val_r_square: 0.9950\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.5028 - r_square: 0.9893 - val_loss: 0.1117 - val_r_square: 0.9977\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 25s 87ms/step - loss: 0.4861 - r_square: 0.9896 - val_loss: 0.5173 - val_r_square: 0.9892\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 25s 88ms/step - loss: 0.4540 - r_square: 0.9903 - val_loss: 0.8247 - val_r_square: 0.9828\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1167 - r_square: 0.9976\n",
      "[CV 8/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.117 total time= 2.9min\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 26s 91ms/step - loss: 2.3633 - r_square: 0.9495 - val_loss: 6.9123 - val_r_square: 0.8629\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 25s 88ms/step - loss: 0.7725 - r_square: 0.9835 - val_loss: 0.4156 - val_r_square: 0.9918\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 25s 90ms/step - loss: 0.6302 - r_square: 0.9865 - val_loss: 1.6003 - val_r_square: 0.9683\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 26s 91ms/step - loss: 0.5938 - r_square: 0.9873 - val_loss: 0.2231 - val_r_square: 0.9956\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 25s 89ms/step - loss: 0.5532 - r_square: 0.9882 - val_loss: 0.2685 - val_r_square: 0.9947\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 25s 89ms/step - loss: 0.5431 - r_square: 0.9884 - val_loss: 0.1331 - val_r_square: 0.9974\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 25s 89ms/step - loss: 0.4750 - r_square: 0.9899 - val_loss: 1.7494 - val_r_square: 0.9653\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 25s 90ms/step - loss: 0.4431 - r_square: 0.9905 - val_loss: 0.8612 - val_r_square: 0.9829\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.1031 - r_square: 0.9977\n",
      "[CV 9/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.103 total time= 3.4min\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 27s 93ms/step - loss: 3.0046 - r_square: 0.9358 - val_loss: 4.7475 - val_r_square: 0.8999\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 26s 91ms/step - loss: 0.7380 - r_square: 0.9842 - val_loss: 1.1136 - val_r_square: 0.9765\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 29s 104ms/step - loss: 0.6244 - r_square: 0.9867 - val_loss: 1.1887 - val_r_square: 0.9749\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 33s 116ms/step - loss: 0.5653 - r_square: 0.9879 - val_loss: 0.5710 - val_r_square: 0.9880\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 33s 116ms/step - loss: 0.5233 - r_square: 0.9888 - val_loss: 0.1073 - val_r_square: 0.9977\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 33s 117ms/step - loss: 0.5041 - r_square: 0.9892 - val_loss: 0.3540 - val_r_square: 0.9925\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 33s 117ms/step - loss: 0.4425 - r_square: 0.9905 - val_loss: 0.4314 - val_r_square: 0.9909\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1082 - r_square: 0.9979\n",
      "[CV 10/10] END activation=relu, batch_norm=True, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.108 total time= 3.6min\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 2.5847 - r_square: 0.9452 - val_loss: 0.3063 - val_r_square: 0.9936\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.2301 - r_square: 0.9951 - val_loss: 0.0797 - val_r_square: 0.9983\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0717 - r_square: 0.9985 - val_loss: 0.0330 - val_r_square: 0.9993\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0445 - r_square: 0.9991 - val_loss: 0.0480 - val_r_square: 0.9990\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0345 - r_square: 0.9993 - val_loss: 0.0139 - val_r_square: 0.9997\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0281 - r_square: 0.9994 - val_loss: 0.0143 - val_r_square: 0.9997\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0252 - r_square: 0.9995 - val_loss: 0.0109 - val_r_square: 0.9998\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0179 - r_square: 0.9996 - val_loss: 0.0079 - val_r_square: 0.9998\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0188 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9998\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0152 - r_square: 0.9997 - val_loss: 0.0082 - val_r_square: 0.9998\n",
      "Epoch 11/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0155 - r_square: 0.9997 - val_loss: 0.0084 - val_r_square: 0.9998\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0075 - r_square: 0.9998\n",
      "[CV 1/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.007 total time=  55.6s\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 21ms/step - loss: 76.3937 - r_square: -0.6178 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 76.3936 - r_square: -0.6178 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 6s 21ms/step - loss: 76.3937 - r_square: -0.6178 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 75.4973 - r_square: -0.6188\n",
      "[CV 2/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-75.497 total time=  18.7s\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 7s 25ms/step - loss: 2.5897 - r_square: 0.9452 - val_loss: 0.3112 - val_r_square: 0.9935\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.2580 - r_square: 0.9945 - val_loss: 0.1618 - val_r_square: 0.9966\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0759 - r_square: 0.9984 - val_loss: 0.0730 - val_r_square: 0.9985\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0498 - r_square: 0.9989 - val_loss: 0.0221 - val_r_square: 0.9995\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 0.0353 - r_square: 0.9993 - val_loss: 0.0279 - val_r_square: 0.9994\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 0.0286 - r_square: 0.9994 - val_loss: 0.0135 - val_r_square: 0.9997\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 0.0254 - r_square: 0.9995 - val_loss: 0.0209 - val_r_square: 0.9996\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 5s 19ms/step - loss: 0.0219 - r_square: 0.9995 - val_loss: 0.0218 - val_r_square: 0.9995\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0135 - r_square: 0.9997\n",
      "[CV 3/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.014 total time=  47.0s\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 76.3646 - r_square: -0.6184 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 76.3647 - r_square: -0.6184 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 76.3647 - r_square: -0.6184 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 75.7061 - r_square: -0.6145\n",
      "[CV 4/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-75.706 total time=  17.2s\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 17.5191 - r_square: 0.6297 - val_loss: 0.4732 - val_r_square: 0.9901\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.3135 - r_square: 0.9934 - val_loss: 0.1377 - val_r_square: 0.9971\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.1057 - r_square: 0.9978 - val_loss: 0.0625 - val_r_square: 0.9987\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0649 - r_square: 0.9986 - val_loss: 0.0407 - val_r_square: 0.9992\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0452 - r_square: 0.9990 - val_loss: 0.0229 - val_r_square: 0.9995\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0353 - r_square: 0.9993 - val_loss: 0.0167 - val_r_square: 0.9997\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0284 - r_square: 0.9994 - val_loss: 0.0162 - val_r_square: 0.9997\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 0.0228 - r_square: 0.9995 - val_loss: 0.0113 - val_r_square: 0.9998\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0205 - r_square: 0.9996 - val_loss: 0.0180 - val_r_square: 0.9996\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0233 - r_square: 0.9995 - val_loss: 0.0305 - val_r_square: 0.9994\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0110 - r_square: 0.9998\n",
      "[CV 5/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.011 total time=  52.2s\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 2.9503 - r_square: 0.9374 - val_loss: 0.3149 - val_r_square: 0.9934\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.2052 - r_square: 0.9956 - val_loss: 0.4697 - val_r_square: 0.9902\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 5s 18ms/step - loss: 0.0988 - r_square: 0.9979 - val_loss: 0.0392 - val_r_square: 0.9992\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0472 - r_square: 0.9990 - val_loss: 0.0465 - val_r_square: 0.9990\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0349 - r_square: 0.9993 - val_loss: 0.0420 - val_r_square: 0.9991\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0397 - r_square: 0.9992\n",
      "[CV 6/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.040 total time=  27.1s\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 76.0935 - r_square: -0.6190 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 18ms/step - loss: 76.0934 - r_square: -0.6190 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 76.0935 - r_square: -0.6190 - val_loss: 77.2852 - val_r_square: -0.6111\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 77.6589 - r_square: -0.6100\n",
      "[CV 7/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-77.659 total time=  17.2s\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 2.9318 - r_square: 0.9375 - val_loss: 0.3121 - val_r_square: 0.9935\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.2126 - r_square: 0.9955 - val_loss: 0.0891 - val_r_square: 0.9981\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0724 - r_square: 0.9985 - val_loss: 0.0452 - val_r_square: 0.9991\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0465 - r_square: 0.9990 - val_loss: 0.0248 - val_r_square: 0.9995\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0431 - r_square: 0.9991 - val_loss: 0.0164 - val_r_square: 0.9997\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0253 - r_square: 0.9995 - val_loss: 0.0143 - val_r_square: 0.9997\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0252 - r_square: 0.9995 - val_loss: 0.0128 - val_r_square: 0.9997\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0210 - r_square: 0.9996 - val_loss: 0.0306 - val_r_square: 0.9994\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0205 - r_square: 0.9996 - val_loss: 0.0740 - val_r_square: 0.9985\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0129 - r_square: 0.9997\n",
      "[CV 8/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.013 total time=  46.3s\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 21ms/step - loss: 75.8458 - r_square: -0.6202 - val_loss: 80.1366 - val_r_square: -0.5894\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 75.8459 - r_square: -0.6202 - val_loss: 80.1366 - val_r_square: -0.5894\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 75.8458 - r_square: -0.6202 - val_loss: 80.1366 - val_r_square: -0.5894\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 74.3089 - r_square: -0.6450\n",
      "[CV 9/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-74.309 total time=  17.2s\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_122 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 2.7301 - r_square: 0.9417 - val_loss: 0.3461 - val_r_square: 0.9927\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.2330 - r_square: 0.9950 - val_loss: 0.0822 - val_r_square: 0.9983\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0780 - r_square: 0.9983 - val_loss: 0.0842 - val_r_square: 0.9982\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0474 - r_square: 0.9990 - val_loss: 0.0235 - val_r_square: 0.9995\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0363 - r_square: 0.9992 - val_loss: 0.0176 - val_r_square: 0.9996\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0283 - r_square: 0.9994 - val_loss: 0.0143 - val_r_square: 0.9997\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0240 - r_square: 0.9995 - val_loss: 0.0286 - val_r_square: 0.9994\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0208 - r_square: 0.9996 - val_loss: 0.0107 - val_r_square: 0.9998\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0175 - r_square: 0.9996 - val_loss: 0.0193 - val_r_square: 0.9996\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0177 - r_square: 0.9996 - val_loss: 0.0075 - val_r_square: 0.9998\n",
      "Epoch 11/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0138 - r_square: 0.9997 - val_loss: 0.0061 - val_r_square: 0.9999\n",
      "Epoch 12/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0149 - r_square: 0.9997 - val_loss: 0.0082 - val_r_square: 0.9998\n",
      "Epoch 13/50\n",
      "282/282 [==============================] - 5s 17ms/step - loss: 0.0120 - r_square: 0.9997 - val_loss: 0.0145 - val_r_square: 0.9997\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.0060 - r_square: 0.9999\n",
      "[CV 10/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.0, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.006 total time= 1.1min\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 31s 107ms/step - loss: 2.9472 - r_square: 0.9375 - val_loss: 0.3515 - val_r_square: 0.9927\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 29s 104ms/step - loss: 0.6344 - r_square: 0.9865 - val_loss: 0.3424 - val_r_square: 0.9929\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 30s 105ms/step - loss: 0.4673 - r_square: 0.9901 - val_loss: 0.0952 - val_r_square: 0.9980\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 30s 107ms/step - loss: 0.4432 - r_square: 0.9906 - val_loss: 0.0366 - val_r_square: 0.9992\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 30s 107ms/step - loss: 0.4226 - r_square: 0.9910 - val_loss: 0.0578 - val_r_square: 0.9988\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 30s 108ms/step - loss: 0.4055 - r_square: 0.9914 - val_loss: 0.0447 - val_r_square: 0.9991\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0372 - r_square: 0.9992\n",
      "[CV 1/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.037 total time= 3.0min\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 32s 111ms/step - loss: 6.4251 - r_square: 0.8639 - val_loss: 0.5714 - val_r_square: 0.9881\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 30s 107ms/step - loss: 0.7532 - r_square: 0.9840 - val_loss: 0.2471 - val_r_square: 0.9948\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 30s 108ms/step - loss: 0.6032 - r_square: 0.9872 - val_loss: 0.1232 - val_r_square: 0.9974\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 31s 109ms/step - loss: 0.4970 - r_square: 0.9895 - val_loss: 0.0830 - val_r_square: 0.9983\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 31s 110ms/step - loss: 0.4514 - r_square: 0.9904 - val_loss: 0.1091 - val_r_square: 0.9977\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 31s 110ms/step - loss: 0.4337 - r_square: 0.9908 - val_loss: 0.0312 - val_r_square: 0.9993\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 31s 111ms/step - loss: 0.4300 - r_square: 0.9909 - val_loss: 0.0315 - val_r_square: 0.9993\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 31s 110ms/step - loss: 0.3962 - r_square: 0.9916 - val_loss: 0.5500 - val_r_square: 0.9885\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0318 - r_square: 0.9993\n",
      "[CV 2/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.032 total time= 4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_132 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 33s 115ms/step - loss: 3.1627 - r_square: 0.9331 - val_loss: 0.4220 - val_r_square: 0.9912\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 32s 112ms/step - loss: 0.6642 - r_square: 0.9860 - val_loss: 0.1548 - val_r_square: 0.9968\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 32s 113ms/step - loss: 0.4535 - r_square: 0.9904 - val_loss: 0.1485 - val_r_square: 0.9969\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 32s 113ms/step - loss: 0.3925 - r_square: 0.9917 - val_loss: 0.0618 - val_r_square: 0.9987\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 32s 113ms/step - loss: 0.3854 - r_square: 0.9919 - val_loss: 0.1150 - val_r_square: 0.9976\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 32s 114ms/step - loss: 0.3691 - r_square: 0.9922 - val_loss: 0.0296 - val_r_square: 0.9994\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 32s 114ms/step - loss: 0.3401 - r_square: 0.9928 - val_loss: 0.0441 - val_r_square: 0.9991\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 33s 116ms/step - loss: 0.3338 - r_square: 0.9929 - val_loss: 0.0211 - val_r_square: 0.9996\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 33s 116ms/step - loss: 0.3360 - r_square: 0.9929 - val_loss: 0.0672 - val_r_square: 0.9986\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 33s 116ms/step - loss: 0.3452 - r_square: 0.9927 - val_loss: 0.0302 - val_r_square: 0.9994\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0212 - r_square: 0.9995\n",
      "[CV 3/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.021 total time= 5.4min\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 34s 120ms/step - loss: 2.8440 - r_square: 0.9397 - val_loss: 0.4108 - val_r_square: 0.9914\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 33s 117ms/step - loss: 0.7322 - r_square: 0.9845 - val_loss: 0.2086 - val_r_square: 0.9957\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 33s 118ms/step - loss: 0.5530 - r_square: 0.9883 - val_loss: 0.0785 - val_r_square: 0.9984\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 33s 118ms/step - loss: 0.4434 - r_square: 0.9906 - val_loss: 0.0761 - val_r_square: 0.9984\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 34s 121ms/step - loss: 0.4296 - r_square: 0.9909 - val_loss: 0.0403 - val_r_square: 0.9992\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 34s 120ms/step - loss: 0.4527 - r_square: 0.9904 - val_loss: 0.0394 - val_r_square: 0.9992\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 33s 119ms/step - loss: 0.4086 - r_square: 0.9913 - val_loss: 0.0757 - val_r_square: 0.9984\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 33s 119ms/step - loss: 0.4057 - r_square: 0.9914 - val_loss: 0.0386 - val_r_square: 0.9992\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 34s 119ms/step - loss: 0.3930 - r_square: 0.9917 - val_loss: 0.0542 - val_r_square: 0.9989\n",
      "Epoch 10/50\n",
      "282/282 [==============================] - 34s 120ms/step - loss: 0.4043 - r_square: 0.9914 - val_loss: 0.0746 - val_r_square: 0.9984\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0386 - r_square: 0.9992\n",
      "[CV 4/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.039 total time= 5.6min\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 36s 126ms/step - loss: 2.8135 - r_square: 0.9405 - val_loss: 0.7521 - val_r_square: 0.9843\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 35s 123ms/step - loss: 0.7397 - r_square: 0.9844 - val_loss: 0.2265 - val_r_square: 0.9953\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 34s 122ms/step - loss: 0.5673 - r_square: 0.9880 - val_loss: 0.0798 - val_r_square: 0.9983\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 34s 122ms/step - loss: 0.4701 - r_square: 0.9901 - val_loss: 0.0782 - val_r_square: 0.9984\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 35s 123ms/step - loss: 0.4628 - r_square: 0.9902 - val_loss: 0.0353 - val_r_square: 0.9993\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 35s 123ms/step - loss: 0.4599 - r_square: 0.9903 - val_loss: 0.1713 - val_r_square: 0.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "282/282 [==============================] - 35s 124ms/step - loss: 0.4464 - r_square: 0.9906 - val_loss: 0.1026 - val_r_square: 0.9979\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0350 - r_square: 0.9992\n",
      "[CV 5/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.035 total time= 4.1min\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 36s 127ms/step - loss: 3.0804 - r_square: 0.9346 - val_loss: 0.7454 - val_r_square: 0.9845\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 35s 124ms/step - loss: 0.7277 - r_square: 0.9846 - val_loss: 0.2785 - val_r_square: 0.9942\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 35s 125ms/step - loss: 0.5928 - r_square: 0.9874 - val_loss: 0.1576 - val_r_square: 0.9967\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 35s 125ms/step - loss: 0.4496 - r_square: 0.9905 - val_loss: 0.0807 - val_r_square: 0.9983\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 35s 126ms/step - loss: 0.4249 - r_square: 0.9910 - val_loss: 0.1206 - val_r_square: 0.9975\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 36s 126ms/step - loss: 0.4008 - r_square: 0.9915 - val_loss: 0.0256 - val_r_square: 0.9995\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 36s 127ms/step - loss: 0.3868 - r_square: 0.9918 - val_loss: 0.0313 - val_r_square: 0.9993\n",
      "Epoch 8/50\n",
      "282/282 [==============================] - 36s 127ms/step - loss: 0.3486 - r_square: 0.9926 - val_loss: 0.1509 - val_r_square: 0.9969\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0259 - r_square: 0.9995\n",
      "[CV 6/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.026 total time= 4.8min\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 37s 131ms/step - loss: 3.5156 - r_square: 0.9252 - val_loss: 0.3991 - val_r_square: 0.9917\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 36s 128ms/step - loss: 0.7439 - r_square: 0.9842 - val_loss: 0.3761 - val_r_square: 0.9922\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 36s 129ms/step - loss: 0.6245 - r_square: 0.9867 - val_loss: 0.1640 - val_r_square: 0.9966\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 36s 129ms/step - loss: 0.4727 - r_square: 0.9899 - val_loss: 0.0798 - val_r_square: 0.9983\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 37s 130ms/step - loss: 0.4213 - r_square: 0.9910 - val_loss: 0.0378 - val_r_square: 0.9992\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 37s 130ms/step - loss: 0.3805 - r_square: 0.9919 - val_loss: 0.0684 - val_r_square: 0.9986\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 37s 131ms/step - loss: 0.3761 - r_square: 0.9920 - val_loss: 0.1458 - val_r_square: 0.9970\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0387 - r_square: 0.9992\n",
      "[CV 7/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.039 total time= 4.3min\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 39s 136ms/step - loss: 2.5092 - r_square: 0.9465 - val_loss: 0.5847 - val_r_square: 0.9878\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 37s 131ms/step - loss: 0.5750 - r_square: 0.9877 - val_loss: 0.2223 - val_r_square: 0.9954\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 37s 132ms/step - loss: 0.4078 - r_square: 0.9913 - val_loss: 0.0944 - val_r_square: 0.9980\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 37s 133ms/step - loss: 0.3111 - r_square: 0.9934 - val_loss: 0.0391 - val_r_square: 0.9992\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 38s 133ms/step - loss: 0.2860 - r_square: 0.9939 - val_loss: 0.0274 - val_r_square: 0.9994\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 44s 158ms/step - loss: 0.2940 - r_square: 0.9937 - val_loss: 0.0374 - val_r_square: 0.9992\n",
      "Epoch 7/50\n",
      "282/282 [==============================] - 51s 179ms/step - loss: 0.2846 - r_square: 0.9939 - val_loss: 0.0247 - val_r_square: 0.9995\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 51s 179ms/step - loss: 0.2675 - r_square: 0.9943 - val_loss: 0.0253 - val_r_square: 0.9995\n",
      "Epoch 9/50\n",
      "282/282 [==============================] - 51s 179ms/step - loss: 0.2732 - r_square: 0.9942 - val_loss: 0.0524 - val_r_square: 0.9989\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.0252 - r_square: 0.9995\n",
      "[CV 8/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.025 total time= 6.4min\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 54s 188ms/step - loss: 4.7097 - r_square: 0.8994 - val_loss: 0.5224 - val_r_square: 0.9896\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 51s 181ms/step - loss: 0.7036 - r_square: 0.9850 - val_loss: 0.2089 - val_r_square: 0.9959\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 51s 181ms/step - loss: 0.5104 - r_square: 0.9891 - val_loss: 0.0702 - val_r_square: 0.9986\n",
      "Epoch 4/50\n",
      "282/282 [==============================] - 51s 181ms/step - loss: 0.4085 - r_square: 0.9913 - val_loss: 0.0688 - val_r_square: 0.9986\n",
      "Epoch 5/50\n",
      "282/282 [==============================] - 51s 182ms/step - loss: 0.3902 - r_square: 0.9917 - val_loss: 0.1438 - val_r_square: 0.9971\n",
      "Epoch 6/50\n",
      "282/282 [==============================] - 51s 182ms/step - loss: 0.4007 - r_square: 0.9914 - val_loss: 0.0976 - val_r_square: 0.9981\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.0659 - r_square: 0.9985\n",
      "[CV 9/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-0.066 total time= 5.2min\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,617\n",
      "Trainable params: 175,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "282/282 [==============================] - 54s 189ms/step - loss: 75.8458 - r_square: -0.6202 - val_loss: 76.9001 - val_r_square: -0.6211\n",
      "Epoch 2/50\n",
      "282/282 [==============================] - 52s 184ms/step - loss: 75.8459 - r_square: -0.6202 - val_loss: 76.9001 - val_r_square: -0.6211\n",
      "Epoch 3/50\n",
      "282/282 [==============================] - 52s 185ms/step - loss: 75.8458 - r_square: -0.6202 - val_loss: 76.9001 - val_r_square: -0.6211\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 80.1347 - r_square: -0.5855\n",
      "[CV 10/10] END activation=relu, batch_norm=False, batch_size=2048, data_length=1000000, dropout_rate=0.1, initializer=<keras.initializers.initializers_v2.RandomUniform object at 0x16c4ccb50>, layer_number=3, lr_0=0.001, neuron_decrease=2, neuron_number=512;, score=-80.135 total time= 2.7min\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 512)               3072      \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " Final_1D_output (Dense)     (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,457\n",
      "Trainable params: 177,537\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 19s 56ms/step - loss: 2.4839 - r_square: 0.9473 - val_loss: 5.0775 - val_r_square: 0.8939\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4330 - r_square: 0.9908 - val_loss: 0.4038 - val_r_square: 0.9916\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2489 - r_square: 0.9947 - val_loss: 0.1319 - val_r_square: 0.9972\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2138 - r_square: 0.9955 - val_loss: 0.1030 - val_r_square: 0.9978\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.1680 - r_square: 0.9964 - val_loss: 0.0751 - val_r_square: 0.9984\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.1656 - r_square: 0.9965 - val_loss: 1.1791 - val_r_square: 0.9754\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.1382 - r_square: 0.9971 - val_loss: 0.0718 - val_r_square: 0.9985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.1339 - r_square: 0.9972 - val_loss: 0.0830 - val_r_square: 0.9983\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.1141 - r_square: 0.9976 - val_loss: 0.1158 - val_r_square: 0.9976\n",
      "5319.618263\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "grid_search_results = grid_search.fit(X_train,y_train,callbacks=[callbacks],validation_split=0.2,\\\n",
    "                                         epochs = 50)\n",
    "end = datetime.now()\n",
    "total_time = (end-start).total_seconds()\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed26de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json_test = grid_search_results.best_estimator_.model.to_json()\n",
    "with open(\"results/grid_results_greeks/model_extra_greeks.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json_test)\n",
    "# serialize weights to HDF5\n",
    "grid_search_results.best_estimator_.model.save_weights(\"results/grid_results_greeks/model_extra_greeks.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea2841eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "search_params_test = grid_search_results.best_params_\n",
    "\n",
    "a_file_test = open(\"results/grid_results_greeks/search_params_extra_greeks.pkl\", \"wb\")\n",
    "pickle.dump(search_params_test, a_file_test)\n",
    "a_file_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9edfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hist_test = grid_search_results.best_estimator_.model.history\n",
    "train_hist_test = pd.DataFrame(model_hist_test.history)\n",
    "train_hist_test.to_csv('results/grid_results_greeks/train_hist_extra_greeks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9b395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor)",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
